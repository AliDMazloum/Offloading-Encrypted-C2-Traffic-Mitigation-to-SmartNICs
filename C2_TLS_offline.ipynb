{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cb74dcd-7be5-4c67-a13e-58628e936ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5ce0ab-2d37-450e-9d64-23a642bf3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['client_hello_len','client_hello_ext_num','server_hello_len','server_hello_ext_num','tls_version']\n",
    "\n",
    "log_directory_benign = \"datasets/DoHBrw/benign/zeek_logs\"\n",
    "\n",
    "log_files_benign = [f for f in os.listdir(log_directory_benign) if f.endswith('.log')]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for log_file in log_files_benign:\n",
    "    file_path = os.path.join(log_directory_benign, log_file)\n",
    "    df = pd.read_csv(file_path, sep=\",\", header=None, skiprows=8, low_memory=False)  # or change delimiter depending on the log format\n",
    "    df = df.iloc[:-1]\n",
    "    df.replace(\"-\", pd.NA, inplace=True)\n",
    "    df = df.dropna()\n",
    "    df_list.append(df)\n",
    "\n",
    "df_doh_benign= pd.concat(df_list, ignore_index=True)\n",
    "df_doh_benign = shuffle(df_doh_benign, random_state=42)\n",
    "df_doh_benign.reset_index(drop=True, inplace=True)\n",
    "df_doh_benign = df_doh_benign.set_axis(headers, axis=1)\n",
    "df_doh_benign['c2'] = 0\n",
    "df_doh_benign['source'] = 'DoH'\n",
    "###########################################################################################################################\n",
    "log_directory_malicious = \"datasets/DoHBrw/malicious/zeek_logs\"\n",
    "\n",
    "log_files_malicious = [f for f in os.listdir(log_directory_malicious) if f.endswith('.log')]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for log_file in log_files_malicious:\n",
    "    file_path = os.path.join(log_directory_malicious, log_file)\n",
    "    df = pd.read_csv(file_path, sep=\",\", header=None, skiprows=8, low_memory=False)  # or change delimiter depending on the log format\n",
    "    df = df.iloc[:-1]\n",
    "    df.replace(\"-\", pd.NA, inplace=True)\n",
    "    df = df.dropna()\n",
    "    df_list.append(df)\n",
    "\n",
    "df_doh_malicious= pd.concat(df_list, ignore_index=True)\n",
    "df_doh_malicious = shuffle(df_doh_malicious, random_state=42)\n",
    "df_doh_malicious.reset_index(drop=True, inplace=True)\n",
    "df_doh_malicious = df_doh_malicious.set_axis(headers, axis=1)\n",
    "df_doh_malicious['c2'] = 1\n",
    "df_doh_malicious['source'] = 'DoH'\n",
    "\n",
    "df_doh = pd.concat([df_doh_malicious,df_doh_benign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "807c3644-5f0c-4c5c-ad86-1b1fb22c532f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_hello_len</th>\n",
       "      <th>client_hello_ext_num</th>\n",
       "      <th>server_hello_len</th>\n",
       "      <th>server_hello_ext_num</th>\n",
       "      <th>tls_version</th>\n",
       "      <th>c2</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>508</td>\n",
       "      <td>17.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>508</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>10.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>508</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>508</td>\n",
       "      <td>12.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502719</th>\n",
       "      <td>508</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502720</th>\n",
       "      <td>508</td>\n",
       "      <td>12.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502721</th>\n",
       "      <td>508</td>\n",
       "      <td>14.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502722</th>\n",
       "      <td>508</td>\n",
       "      <td>12.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502723</th>\n",
       "      <td>508</td>\n",
       "      <td>17.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DoH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502724 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_hello_len  client_hello_ext_num  server_hello_len  \\\n",
       "0                   508                  17.0              66.0   \n",
       "1                   508                  17.0              72.0   \n",
       "2                   252                  10.0             118.0   \n",
       "3                   508                  17.0              61.0   \n",
       "4                   508                  12.0             118.0   \n",
       "...                 ...                   ...               ...   \n",
       "502719              508                  17.0              80.0   \n",
       "502720              508                  12.0              94.0   \n",
       "502721              508                  14.0             118.0   \n",
       "502722              508                  12.0              93.0   \n",
       "502723              508                  17.0             100.0   \n",
       "\n",
       "        server_hello_ext_num  tls_version  c2 source  \n",
       "0                        4.0          3.0   0    DoH  \n",
       "1                        4.0          3.0   0    DoH  \n",
       "2                        2.0          3.0   1    DoH  \n",
       "3                        4.0          3.0   0    DoH  \n",
       "4                        2.0          3.0   0    DoH  \n",
       "...                      ...          ...  ..    ...  \n",
       "502719                   6.0          3.0   0    DoH  \n",
       "502720                   3.0          3.0   0    DoH  \n",
       "502721                   2.0          3.0   0    DoH  \n",
       "502722                   4.0          3.0   0    DoH  \n",
       "502723                   5.0          3.0   0    DoH  \n",
       "\n",
       "[502724 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = df_doh\n",
    "df_all = shuffle(df_all, random_state=42)\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06deb37-18a2-4a14-83da-a0f0fc40afbf",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a804b0e-d0dd-4086-982b-15e4148549d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_all.loc[:,headers].values.astype(np.float64)\n",
    "y = df_all.loc[:,\"c2\"].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19a2740e-ecdc-4a75-ad17-6a9018f86a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y , \n",
    "                                   random_state=42,  \n",
    "                                   test_size=0.25,  \n",
    "                                   shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5ffbb-a2df-4c6e-9fe1-3743d55bb96f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79435ce2-e1ae-44f6-bd95-1b58b7d9cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(max_depth=20, n_estimators = 5, max_leaf_nodes=500, n_jobs=4, random_state=42, bootstrap=False)                              \n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy on test data: {accuracy}\")\n",
    "# print(classification_report(y_test,y_pred))\n",
    "# importances = rf_model.feature_importances_\n",
    "# feature_importances = pd.DataFrame({'feature': headers, 'importance': importances})\n",
    "# feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "# feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7791bded-9d86-428c-908a-9b80bb5a9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(rf_model, open(\"RF_DPDK.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe2ed7",
   "metadata": {},
   "source": [
    "# Transform RF model into Json Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8143ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved to rf_model.json\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# Function to extract information from each tree in the Random Forest\n",
    "def tree_to_json(tree):\n",
    "    # Get the decision tree's internal attributes\n",
    "    n_nodes = tree.tree_.node_count\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    feature = tree.tree_.feature\n",
    "    threshold = tree.tree_.threshold\n",
    "    class_names = tree.classes_\n",
    "\n",
    "    nodes = []\n",
    "    for i in range(n_nodes):\n",
    "        node = {}\n",
    "        # If it's a leaf node, assign class label\n",
    "        if children_left[i] == children_right[i]:\n",
    "            node['is_leaf'] = True\n",
    "            # Extract class counts/probabilities and assign the class with the max count/probability\n",
    "            class_counts = tree.tree_.value[i, 0]\n",
    "            class_label = class_counts.argmax()  # Get the index of the maximum count\n",
    "            node['class_label'] = int(class_names[class_label])  # Get the corresponding class label\n",
    "        else:\n",
    "            node['is_leaf'] = False\n",
    "            node['class_label'] = -10\n",
    "\n",
    "        node['feature'] = feature[i] if feature[i] != -2 else -2  # -2 indicates no split (leaf)\n",
    "        node['threshold'] = threshold[i]\n",
    "        node['left_child'] = children_left[i]\n",
    "        node['right_child'] = children_right[i]\n",
    "        \n",
    "        nodes.append(node)\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "# Function to convert the Random Forest model to JSON format\n",
    "def rf_to_json(rf_model):\n",
    "    # print(rf_model)\n",
    "    rf_data = {\n",
    "        'n_estimators': len(rf_model.estimators_),\n",
    "        'max_depth': rf_model.max_depth,\n",
    "        'feature_importances': rf_model.feature_importances_.tolist(),\n",
    "        'estimators': []\n",
    "    }\n",
    "\n",
    "    # Convert each estimator (tree) to JSON\n",
    "    for estimator in rf_model.estimators_:\n",
    "        # For each tree (estimator), get the nodes and relevant details\n",
    "        estimators_data = {\n",
    "            'n_nodes': estimator.tree_.node_count,\n",
    "            'children_left': estimator.tree_.children_left.tolist(),\n",
    "            'children_right': estimator.tree_.children_right.tolist(),\n",
    "            'feature': estimator.tree_.feature.tolist(),\n",
    "            'threshold': estimator.tree_.threshold.tolist(),\n",
    "            'class_label': [] , # Initialize a list for class labels\n",
    "            'leaves' : []\n",
    "        }\n",
    "        # Extract class labels from the tree's value attribute\n",
    "        for i in range(estimator.tree_.node_count):\n",
    "            if estimator.tree_.children_left[i] == estimator.tree_.children_right[i]:\n",
    "                estimators_data['leaves'].append(1)\n",
    "                class_counts = estimator.tree_.value[i, 0]  # Get the counts for each class at the leaf node\n",
    "                max_class_index = class_counts.argmax()  # Get the index of the max class count\n",
    "                estimators_data['class_label'].append(int(estimator.classes_[max_class_index]))  # Add the class label\n",
    "            else:\n",
    "                estimators_data['leaves'].append(0)\n",
    "                estimators_data['class_label'].append(-10)  # Add the class label\n",
    "\n",
    "        rf_data['estimators'].append(estimators_data)\n",
    "\n",
    "    return rf_data\n",
    "\n",
    "# Load the Random Forest model from the .pkl file\n",
    "with open('RF_DPDK.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)\n",
    "\n",
    "# Convert the model to JSON\n",
    "rf_json = rf_to_json(rf_model)\n",
    "\n",
    "# Write the JSON to a file\n",
    "with open('rf_model.json', 'w') as json_file:\n",
    "    json.dump(rf_json, json_file, indent=4)\n",
    "\n",
    "print(\"Random Forest model saved to rf_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a17f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
